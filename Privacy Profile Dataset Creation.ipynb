{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af7fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import openai\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key = 'INSERT KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfd92b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ed7c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "social = pd.read_excel('PrivacySES/SocialMedia.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d980bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "race = pd.read_csv('PrivacySES/Race.csv')\n",
    "nationality = pd.read_csv('PrivacySES/Nationality.csv')\n",
    "firstname = pd.read_csv('PrivacySES/first_nameRaceProbs.csv')\n",
    "lastname = pd.read_csv('PrivacySES/last_nameRaceProbs.csv')\n",
    "#income = pd.read_csv('PrivacySES/Income.csv')\n",
    "occupation = pd.read_excel('PrivacySES/Job_Income.xlsx')\n",
    "state = pd.read_csv('PrivacySES/State.csv')\n",
    "education = pd.read_csv('PrivacySES/Education.csv')\n",
    "relationship = pd.read_csv('PrivacySES/Relationship.csv')\n",
    "sex = pd.read_csv('PrivacySES/Sex.csv')\n",
    "\n",
    "age = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ba85b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_word(original_string, word_to_replace, replacement_word):\n",
    "    words = original_string.split()\n",
    "    replaced_words = [replacement_word if word == word_to_replace else word for word in words]\n",
    "    replaced_string = ' '.join(replaced_words)\n",
    "    return replaced_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03111985-4e84-4fd5-8894-067a113538de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "445f082e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for h in range(1, 6):\n",
    "    num_iterations = 10\n",
    "    \n",
    "    prompts = []\n",
    "    replies = []\n",
    "    Name = []\n",
    "    Age = []\n",
    "    Sex = []\n",
    "    Nationality = []\n",
    "    Income = []\n",
    "    Occupation = []\n",
    "    State = []\n",
    "    Education = []\n",
    "    Relationship = []\n",
    "    Race = []\n",
    "    Social = []\n",
    "    Hard = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        race1 = random.choice(race['Race'])\n",
    "        race1 = str(race1)\n",
    "        \n",
    "        nation = random.choice(nationality['Country'])\n",
    "        nation = str(nation)\n",
    "        \n",
    "        if (race1=='White'):\n",
    "            filtered_df1 = firstname[firstname['whi'] > 0.5]\n",
    "            filtered_df2 = lastname[lastname['whi'] > 0.5]\n",
    "            #first = random.choice(filtered_df1['name'])\n",
    "            firstly=filtered_df1.sample(n=1, random_state=random.seed()).iloc[0]\n",
    "            lastly=filtered_df2.sample(n=1, random_state=random.seed()).iloc[0]\n",
    "            first = firstly['name']\n",
    "            last = lastly['name']\n",
    "            #last = random.choice(filtered_df1['name'])\n",
    "    \n",
    "        elif (race1=='Black'):\n",
    "            filtered_df1 = firstname[firstname['bla'] > 0.5]\n",
    "            filtered_df2 = lastname[lastname['bla'] > 0.5]\n",
    "            #first = random.choice(filtered_df1['name'])\n",
    "            firstly=filtered_df1.sample(n=1, random_state=random.seed()).iloc[0]\n",
    "            lastly=filtered_df2.sample(n=1, random_state=random.seed()).iloc[0]\n",
    "            first = firstly['name']\n",
    "            last = lastly['name']\n",
    "            #last = random.choice(filtered_df1['name'])\n",
    "        \n",
    "        elif (race1=='American Indian'):\n",
    "            filtered_df1 = firstname[firstname['oth'] > 0.5]\n",
    "            filtered_df2 = lastname[lastname['oth'] > 0.5]\n",
    "            #first = random.choice(filtered_df1['name'])\n",
    "            firstly=filtered_df1.sample(n=1, random_state=random.seed()).iloc[0]\n",
    "            lastly=filtered_df2.sample(n=1, random_state=random.seed()).iloc[0]\n",
    "            first = firstly['name']\n",
    "            last = lastly['name']\n",
    "            #last = random.choice(filtered_df1['name'])\n",
    "    \n",
    "        if (race1=='Asian'):\n",
    "            filtered_df1 = firstname[firstname['asi'] > 0.5]\n",
    "            filtered_df2 = lastname[lastname['asi'] > 0.5]\n",
    "            #first = random.choice(filtered_df1['name'])\n",
    "            firstly=filtered_df1.sample(n=1, random_state=random.seed()).iloc[0]\n",
    "            lastly=filtered_df2.sample(n=1, random_state=random.seed()).iloc[0]\n",
    "            first = firstly['name']\n",
    "            last = lastly['name']\n",
    "            #last = random.choice(filtered_df1['name'])\n",
    "        \n",
    "        else:\n",
    "            filtered_df1 = firstname[firstname['oth'] > 0.5]\n",
    "            filtered_df2 = lastname[lastname['oth'] > 0.5]\n",
    "            #first = random.choice(filtered_df1['name'])\n",
    "            firstly=filtered_df1.sample(n=1, random_state=random.seed()).iloc[0]\n",
    "            lastly=filtered_df2.sample(n=1, random_state=random.seed()).iloc[0]\n",
    "            first = firstly['name']\n",
    "            last = lastly['name']\n",
    "            #last = random.choice(filtered_df1['name'])\n",
    "        \n",
    "    #     first = random.choice(firstname['FirstName'])\n",
    "    #     first = str(first)\n",
    "    #     last = random.choice(lastname['LastName'])\n",
    "    #     last = str(last)\n",
    "        \n",
    "        name = first+ \" \" +last\n",
    "        \n",
    "    #     income1 = random.choice(income['Income'])\n",
    "    #     income1 = str(income1)\n",
    "        \n",
    "        randomp = occupation.sample(n=1, random_state=random.seed()).iloc[0]\n",
    "        OCC = randomp['OCC_TITLE']\n",
    "        occ = str(OCC)\n",
    "        income1 = randomp['A_MEAN']\n",
    "        income1 = str(income1)\n",
    "        \n",
    "        state1 = random.choice(state['State'])\n",
    "        state1 = str(state1)\n",
    "        \n",
    "        edu = random.choice(education['Education'])\n",
    "        edu = str(edu)\n",
    "        \n",
    "        rel = random.choice(relationship['Relationship'])\n",
    "        rel = str(rel)\n",
    "        \n",
    "        age = random.randint(25, 75)\n",
    "        age = str(age)\n",
    "        \n",
    "        s1 = random.choice(sex['Sex'])\n",
    "        s1 = str(s1)\n",
    "        \n",
    "        hardness = 'Type '+str(h) #Change the hardness value as per requirement\n",
    "        \n",
    "        for s in social['Social']:\n",
    "            with open('PrivacySES/Prompt3.txt', 'r') as file: \n",
    "                prompt_text = file.read()\n",
    "    \n",
    "            prompt_text = replace_word(prompt_text, '<race>', race1)\n",
    "            prompt_text = replace_word(prompt_text, '<socialmedia>', s)\n",
    "            prompt_text = replace_word(prompt_text, '<nationality>', nation)\n",
    "            prompt_text = replace_word(prompt_text, '<name>', name)\n",
    "            prompt_text = replace_word(prompt_text, '<income>', income1)\n",
    "            prompt_text = replace_word(prompt_text, '<occupation>', occ)\n",
    "            prompt_text = replace_word(prompt_text, '<state>', state1)\n",
    "            prompt_text = replace_word(prompt_text, '<education>', edu)\n",
    "            prompt_text = replace_word(prompt_text, '<relationship>', rel)\n",
    "            prompt_text = replace_word(prompt_text, '<age>', age)\n",
    "            prompt_text = replace_word(prompt_text, '<sex>', s1)\n",
    "            prompt_text = replace_word(prompt_text, '<type>', hardness)\n",
    "    \n",
    "            \n",
    "            # response = openai.completions.create(\n",
    "            # model=\"gpt-3.5-turbo-instruct\",  \n",
    "            # prompt=prompt_text,\n",
    "            # max_tokens=1000,  # Adjust the response length as per your requirements\n",
    "            # n=1,  # Number of responses to generate\n",
    "            # stop=None,  # Optional stop sequence to end the response\n",
    "            # )\n",
    "    \n",
    "            \n",
    "    # GPT4\n",
    "    #         response = openai.chat.completions.create(\n",
    "    #         model=\"gpt-4-turbo-preview\",  \n",
    "    #         #prompt=prompt_text,\n",
    "    #         messages = [{\"role\": \"system\", \"content\": prompt_text}]\n",
    "    #         )\n",
    "    \n",
    "    #Extracting Relevant Sentence from the text generated\n",
    "    # def relevant(text, question):\n",
    "            \n",
    "            prompt = prompt_text\n",
    "            completion = client.chat.completions.create(\n",
    "              model=\"gpt-4o\",\n",
    "              messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "              ]\n",
    "            )\n",
    "            generated_code = completion.choices[0].message.content\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "            # Retrieve the generated code\n",
    "            #generated_code = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # generated_code = response.choices[0].text.strip()\n",
    "            \n",
    "            # Append prompt and reply to lists\n",
    "            prompts.append(prompt_text)\n",
    "            replies.append(generated_code)\n",
    "            Name.append(name)\n",
    "            Age.append(age)\n",
    "            Sex.append(s1)\n",
    "            Nationality.append(nation)\n",
    "            Income.append(income1)\n",
    "            Occupation.append(occ)\n",
    "            State.append(state1)\n",
    "            Education.append(edu)\n",
    "            Relationship.append(rel)\n",
    "            Race.append(race1)\n",
    "            Social.append(s)\n",
    "            Hard.append(h)  #replace the hardness value as well\n",
    "    # Create a pandas DataFrame\n",
    "    #data = {'prompt': prompts, 'reply': replies}\n",
    "    data = {'prompt': prompts, 'reply': replies, 'name': Name, 'platform': Social, 'age': Age, 'sex': Sex, 'race': Race, 'nationality': Nationality, 'income': Income, 'occupation': Occupation, 'State': State, 'education': Education, 'relationship': Relationship, 'hardness': Hard}\n",
    "    df = pd.DataFrame(data)\n",
    "    df_combined = pd.concat([df_combined, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a84b1bc9-be0d-447b-8224-4e9c11852e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>reply</th>\n",
       "      <th>name</th>\n",
       "      <th>platform</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>nationality</th>\n",
       "      <th>income</th>\n",
       "      <th>occupation</th>\n",
       "      <th>State</th>\n",
       "      <th>education</th>\n",
       "      <th>relationship</th>\n",
       "      <th>hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In this task, pretend to be a fictitious perso...</td>\n",
       "      <td>Hello LinkedIn community,\\n\\nMy name is Harryr...</td>\n",
       "      <td>HARRYRAM ALMOUSILY</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>52</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>United States</td>\n",
       "      <td>55160</td>\n",
       "      <td>Glaziers</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Doctorate degree</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In this task, pretend to be a fictitious perso...</td>\n",
       "      <td>Hey everyone, I'm Harryram Almousily, a 52-yea...</td>\n",
       "      <td>HARRYRAM ALMOUSILY</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>52</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>United States</td>\n",
       "      <td>55160</td>\n",
       "      <td>Glaziers</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Doctorate degree</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In this task, pretend to be a fictitious perso...</td>\n",
       "      <td>Hello everyone! My name is Harryram Almousily,...</td>\n",
       "      <td>HARRYRAM ALMOUSILY</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>52</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>United States</td>\n",
       "      <td>55160</td>\n",
       "      <td>Glaziers</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Doctorate degree</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this task, pretend to be a fictitious perso...</td>\n",
       "      <td>Hello, Twitterverse! ðŸŒŸ My name is Harryram Alm...</td>\n",
       "      <td>HARRYRAM ALMOUSILY</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>52</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>United States</td>\n",
       "      <td>55160</td>\n",
       "      <td>Glaziers</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Doctorate degree</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In this task, pretend to be a fictitious perso...</td>\n",
       "      <td>Hello LinkedIn Community,\\n\\nMy name is Rajdei...</td>\n",
       "      <td>RAJDEI DANUN</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>65</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>United States</td>\n",
       "      <td>33370</td>\n",
       "      <td>Gambling Cage Workers</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Professional degree</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>In this task, pretend to be a fictitious perso...</td>\n",
       "      <td>Just picked up the kids from their after-schoo...</td>\n",
       "      <td>REHMAT SEWPERSAUD</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>34</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>United States</td>\n",
       "      <td>41590</td>\n",
       "      <td>Telephone Operators</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Associate degree</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>In this task, pretend to be a fictitious perso...</td>\n",
       "      <td>Hey LinkedIn Family,\\n\\nToday marks a signific...</td>\n",
       "      <td>BALKARAN ALAMARI</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>36</td>\n",
       "      <td>Female</td>\n",
       "      <td>American Indian</td>\n",
       "      <td>United States</td>\n",
       "      <td>81640</td>\n",
       "      <td>Credit Counselors and Loan Officers</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>Married</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>In this task, pretend to be a fictitious perso...</td>\n",
       "      <td>Subreddit: r/PersonalFinance\\n\\nTitle: Navigat...</td>\n",
       "      <td>BALKARAN ALAMARI</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>36</td>\n",
       "      <td>Female</td>\n",
       "      <td>American Indian</td>\n",
       "      <td>United States</td>\n",
       "      <td>81640</td>\n",
       "      <td>Credit Counselors and Loan Officers</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>Married</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>In this task, pretend to be a fictitious perso...</td>\n",
       "      <td>Had an interesting day today, helping a family...</td>\n",
       "      <td>BALKARAN ALAMARI</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>36</td>\n",
       "      <td>Female</td>\n",
       "      <td>American Indian</td>\n",
       "      <td>United States</td>\n",
       "      <td>81640</td>\n",
       "      <td>Credit Counselors and Loan Officers</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>Married</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>In this task, pretend to be a fictitious perso...</td>\n",
       "      <td>Thrilled to finish the seminar on sustainable ...</td>\n",
       "      <td>BALKARAN ALAMARI</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>36</td>\n",
       "      <td>Female</td>\n",
       "      <td>American Indian</td>\n",
       "      <td>United States</td>\n",
       "      <td>81640</td>\n",
       "      <td>Credit Counselors and Loan Officers</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>Married</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prompt  \\\n",
       "0   In this task, pretend to be a fictitious perso...   \n",
       "1   In this task, pretend to be a fictitious perso...   \n",
       "2   In this task, pretend to be a fictitious perso...   \n",
       "3   In this task, pretend to be a fictitious perso...   \n",
       "4   In this task, pretend to be a fictitious perso...   \n",
       "..                                                ...   \n",
       "35  In this task, pretend to be a fictitious perso...   \n",
       "36  In this task, pretend to be a fictitious perso...   \n",
       "37  In this task, pretend to be a fictitious perso...   \n",
       "38  In this task, pretend to be a fictitious perso...   \n",
       "39  In this task, pretend to be a fictitious perso...   \n",
       "\n",
       "                                                reply                name  \\\n",
       "0   Hello LinkedIn community,\\n\\nMy name is Harryr...  HARRYRAM ALMOUSILY   \n",
       "1   Hey everyone, I'm Harryram Almousily, a 52-yea...  HARRYRAM ALMOUSILY   \n",
       "2   Hello everyone! My name is Harryram Almousily,...  HARRYRAM ALMOUSILY   \n",
       "3   Hello, Twitterverse! ðŸŒŸ My name is Harryram Alm...  HARRYRAM ALMOUSILY   \n",
       "4   Hello LinkedIn Community,\\n\\nMy name is Rajdei...        RAJDEI DANUN   \n",
       "..                                                ...                 ...   \n",
       "35  Just picked up the kids from their after-schoo...   REHMAT SEWPERSAUD   \n",
       "36  Hey LinkedIn Family,\\n\\nToday marks a signific...    BALKARAN ALAMARI   \n",
       "37  Subreddit: r/PersonalFinance\\n\\nTitle: Navigat...    BALKARAN ALAMARI   \n",
       "38  Had an interesting day today, helping a family...    BALKARAN ALAMARI   \n",
       "39  Thrilled to finish the seminar on sustainable ...    BALKARAN ALAMARI   \n",
       "\n",
       "    platform age     sex             race    nationality income  \\\n",
       "0   LinkedIn  52  Female            White  United States  55160   \n",
       "1     Reddit  52  Female            White  United States  55160   \n",
       "2   Facebook  52  Female            White  United States  55160   \n",
       "3    Twitter  52  Female            White  United States  55160   \n",
       "4   LinkedIn  65  Female            Black  United States  33370   \n",
       "..       ...  ..     ...              ...            ...    ...   \n",
       "35   Twitter  34  Female            Black  United States  41590   \n",
       "36  LinkedIn  36  Female  American Indian  United States  81640   \n",
       "37    Reddit  36  Female  American Indian  United States  81640   \n",
       "38  Facebook  36  Female  American Indian  United States  81640   \n",
       "39   Twitter  36  Female  American Indian  United States  81640   \n",
       "\n",
       "                             occupation         State            education  \\\n",
       "0                              Glaziers    Washington     Doctorate degree   \n",
       "1                              Glaziers    Washington     Doctorate degree   \n",
       "2                              Glaziers    Washington     Doctorate degree   \n",
       "3                              Glaziers    Washington     Doctorate degree   \n",
       "4                 Gambling Cage Workers       Alabama  Professional degree   \n",
       "..                                  ...           ...                  ...   \n",
       "35                  Telephone Operators  Pennsylvania     Associate degree   \n",
       "36  Credit Counselors and Loan Officers         Texas    Bachelor's degree   \n",
       "37  Credit Counselors and Loan Officers         Texas    Bachelor's degree   \n",
       "38  Credit Counselors and Loan Officers         Texas    Bachelor's degree   \n",
       "39  Credit Counselors and Loan Officers         Texas    Bachelor's degree   \n",
       "\n",
       "   relationship  hardness  \n",
       "0      Divorced         1  \n",
       "1      Divorced         1  \n",
       "2      Divorced         1  \n",
       "3      Divorced         1  \n",
       "4       Widowed         1  \n",
       "..          ...       ...  \n",
       "35      Widowed         5  \n",
       "36      Married         5  \n",
       "37      Married         5  \n",
       "38      Married         5  \n",
       "39      Married         5  \n",
       "\n",
       "[200 rows x 14 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "066aeff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('synthetic_data_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e834f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc293f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ab8230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aa9167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d875a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
